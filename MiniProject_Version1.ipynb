{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9321f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jt -t chesterish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7004f999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./opt/anaconda3/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in ./opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in ./opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.22.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./opt/anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Collecting git+https://github.com/boudinfl/pke.git\n",
      "  Cloning https://github.com/boudinfl/pke.git to /private/var/folders/m_/0z02_93d5tsc5bxl5gxmp_8c0000gn/T/pip-req-build-qfytaku9\n",
      "  Running command git clone -q https://github.com/boudinfl/pke.git /private/var/folders/m_/0z02_93d5tsc5bxl5gxmp_8c0000gn/T/pip-req-build-qfytaku9\n",
      "  Resolved https://github.com/boudinfl/pke.git to commit a262f98e0669af96df47eedc6fedb5a0d6ecaf80\n",
      "Requirement already satisfied: nltk in ./opt/anaconda3/lib/python3.9/site-packages (from pke==2.0.0) (3.7)\n",
      "Requirement already satisfied: networkx in ./opt/anaconda3/lib/python3.9/site-packages (from pke==2.0.0) (2.6.3)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from pke==2.0.0) (1.22.3)\n",
      "Requirement already satisfied: scipy in ./opt/anaconda3/lib/python3.9/site-packages (from pke==2.0.0) (1.8.0)\n",
      "Requirement already satisfied: sklearn in ./opt/anaconda3/lib/python3.9/site-packages (from pke==2.0.0) (0.0)\n",
      "Requirement already satisfied: unidecode in ./opt/anaconda3/lib/python3.9/site-packages (from pke==2.0.0) (1.2.0)\n",
      "Requirement already satisfied: future in ./opt/anaconda3/lib/python3.9/site-packages (from pke==2.0.0) (0.18.2)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from pke==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: spacy>=3.2.3 in ./opt/anaconda3/lib/python3.9/site-packages (from pke==2.0.0) (3.2.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.7.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (8.0.15)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.9.1)\n",
      "Requirement already satisfied: click<8.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (8.0.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.6.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.27.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (21.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (4.64.0)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (62.1.0)\n",
      "Requirement already satisfied: jinja2 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy>=3.2.3->pke==2.0.0) (3.0.8)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy>=3.2.3->pke==2.0.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (4.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->pke==2.0.0) (2022.4.24)\n",
      "Requirement already satisfied: scikit-learn in ./opt/anaconda3/lib/python3.9/site-packages (from sklearn->pke==2.0.0) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sklearn->pke==2.0.0) (3.1.0)\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.64.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: jinja2 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.1.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (62.1.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.22.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: click<8.1.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in ./opt/anaconda3/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting bert-extractive-summarizer\n",
      "  Using cached bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.2.4-cp39-cp39-macosx_10_9_x86_64.whl (6.3 MB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.0.2-cp39-cp39-macosx_10_13_x86_64.whl (8.0 MB)\n",
      "Collecting scipy>=1.1.0\n",
      "  Using cached scipy-1.8.0-cp39-cp39-macosx_12_0_universal2.macosx_10_9_x86_64.whl (55.6 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting numpy>=1.14.6\n",
      "  Using cached numpy-1.22.3-cp39-cp39-macosx_10_14_x86_64.whl (17.6 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.1-py3-none-any.whl (132 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp39-cp39-macosx_10_9_x86_64.whl (32 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-62.1.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Using cached thinc-8.0.15-cp39-cp39-macosx_10_9_x86_64.whl (639 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.1-py3-none-any.whl (27 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.6-cp39-cp39-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp39-cp39-macosx_10_9_x86_64.whl (106 kB)\n",
      "Collecting click<8.1.0\n",
      "  Using cached click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Using cached spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-cp39-cp39-macosx_10_9_x86_64.whl (2.7 MB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Using cached srsly-2.4.3-cp39-cp39-macosx_10_9_x86_64.whl (457 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.7-cp39-cp39-macosx_10_9_x86_64.whl (5.8 MB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.8-py3-none-any.whl (98 kB)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp39-cp39-macosx_10_9_x86_64.whl (13 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0-cp39-cp39-macosx_10_9_x86_64.whl (197 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp39-cp39-macosx_10_11_x86_64.whl (3.6 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.4.24-cp39-cp39-macosx_10_9_x86_64.whl (288 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "Collecting six\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, pyparsing, numpy, murmurhash, idna, cymem, click, charset-normalizer, certifi, catalogue, wasabi, typer, tqdm, srsly, smart-open, six, setuptools, requests, regex, pyyaml, pydantic, preshed, packaging, MarkupSafe, joblib, filelock, blis, tokenizers, threadpoolctl, thinc, spacy-loggers, spacy-legacy, scipy, sacremoses, pathy, langcodes, jinja2, huggingface-hub, transformers, spacy, scikit-learn, bert-extractive-summarizer\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.9\n",
      "    Uninstalling urllib3-1.26.9:\n",
      "      Successfully uninstalled urllib3-1.26.9\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.2.0\n",
      "    Uninstalling typing-extensions-4.2.0:\n",
      "      Successfully uninstalled typing-extensions-4.2.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.8\n",
      "    Uninstalling pyparsing-3.0.8:\n",
      "      Successfully uninstalled pyparsing-3.0.8\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.3\n",
      "    Uninstalling numpy-1.22.3:\n",
      "      Successfully uninstalled numpy-1.22.3\n",
      "  Attempting uninstall: murmurhash\n",
      "    Found existing installation: murmurhash 1.0.6\n",
      "    Uninstalling murmurhash-1.0.6:\n",
      "      Successfully uninstalled murmurhash-1.0.6\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: cymem\n",
      "    Found existing installation: cymem 2.0.6\n",
      "    Uninstalling cymem-2.0.6:\n",
      "      Successfully uninstalled cymem-2.0.6\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Uninstalling click-8.0.4:\n",
      "      Successfully uninstalled click-8.0.4\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.12\n",
      "    Uninstalling charset-normalizer-2.0.12:\n",
      "      Successfully uninstalled charset-normalizer-2.0.12\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2021.10.8\n",
      "    Uninstalling certifi-2021.10.8:\n",
      "      Successfully uninstalled certifi-2021.10.8\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 2.0.7\n",
      "    Uninstalling catalogue-2.0.7:\n",
      "      Successfully uninstalled catalogue-2.0.7\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 0.9.1\n",
      "    Uninstalling wasabi-0.9.1:\n",
      "      Successfully uninstalled wasabi-0.9.1\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.4.1\n",
      "    Uninstalling typer-0.4.1:\n",
      "      Successfully uninstalled typer-0.4.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.0\n",
      "    Uninstalling tqdm-4.64.0:\n",
      "      Successfully uninstalled tqdm-4.64.0\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 2.4.3\n",
      "    Uninstalling srsly-2.4.3:\n",
      "      Successfully uninstalled srsly-2.4.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 5.2.1\n",
      "    Uninstalling smart-open-5.2.1:\n",
      "      Successfully uninstalled smart-open-5.2.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 62.1.0\n",
      "    Uninstalling setuptools-62.1.0:\n",
      "      Successfully uninstalled setuptools-62.1.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2022.4.24\n",
      "    Uninstalling regex-2022.4.24:\n",
      "      Successfully uninstalled regex-2022.4.24\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.8.2\n",
      "    Uninstalling pydantic-1.8.2:\n",
      "      Successfully uninstalled pydantic-1.8.2\n",
      "  Attempting uninstall: preshed\n",
      "    Found existing installation: preshed 3.0.6\n",
      "    Uninstalling preshed-3.0.6:\n",
      "      Successfully uninstalled preshed-3.0.6\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.1\n",
      "    Uninstalling MarkupSafe-2.1.1:\n",
      "      Successfully uninstalled MarkupSafe-2.1.1\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.6.0\n",
      "    Uninstalling filelock-3.6.0:\n",
      "      Successfully uninstalled filelock-3.6.0\n",
      "  Attempting uninstall: blis\n",
      "    Found existing installation: blis 0.7.7\n",
      "    Uninstalling blis-0.7.7:\n",
      "      Successfully uninstalled blis-0.7.7\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.1.0\n",
      "    Uninstalling threadpoolctl-3.1.0:\n",
      "      Successfully uninstalled threadpoolctl-3.1.0\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.0.15\n",
      "    Uninstalling thinc-8.0.15:\n",
      "      Successfully uninstalled thinc-8.0.15\n",
      "  Attempting uninstall: spacy-loggers\n",
      "    Found existing installation: spacy-loggers 1.0.2\n",
      "    Uninstalling spacy-loggers-1.0.2:\n",
      "      Successfully uninstalled spacy-loggers-1.0.2\n",
      "  Attempting uninstall: spacy-legacy\n",
      "    Found existing installation: spacy-legacy 3.0.9\n",
      "    Uninstalling spacy-legacy-3.0.9:\n",
      "      Successfully uninstalled spacy-legacy-3.0.9\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.8.0\n",
      "    Uninstalling scipy-1.8.0:\n",
      "      Successfully uninstalled scipy-1.8.0\n",
      "  Attempting uninstall: sacremoses\n",
      "    Found existing installation: sacremoses 0.0.49\n",
      "    Uninstalling sacremoses-0.0.49:\n",
      "      Successfully uninstalled sacremoses-0.0.49\n",
      "  Attempting uninstall: pathy\n",
      "    Found existing installation: pathy 0.6.1\n",
      "    Uninstalling pathy-0.6.1:\n",
      "      Successfully uninstalled pathy-0.6.1\n",
      "  Attempting uninstall: langcodes\n",
      "    Found existing installation: langcodes 3.3.0\n",
      "    Uninstalling langcodes-3.3.0:\n",
      "      Successfully uninstalled langcodes-3.3.0\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.1\n",
      "    Uninstalling Jinja2-3.1.1:\n",
      "      Successfully uninstalled Jinja2-3.1.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.5.1\n",
      "    Uninstalling huggingface-hub-0.5.1:\n",
      "      Successfully uninstalled huggingface-hub-0.5.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.18.0\n",
      "    Uninstalling transformers-4.18.0:\n",
      "      Successfully uninstalled transformers-4.18.0\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.2.4\n",
      "    Uninstalling spacy-3.2.4:\n",
      "      Successfully uninstalled spacy-3.2.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: bert-extractive-summarizer\n",
      "    Found existing installation: bert-extractive-summarizer 0.10.1\n",
      "    Uninstalling bert-extractive-summarizer-0.10.1:\n",
      "      Successfully uninstalled bert-extractive-summarizer-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.1 requires ruamel-yaml, which is not installed.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.3 which is incompatible.\n",
      "cookiecutter 1.7.2 requires Jinja2<3.0.0, but you have jinja2 3.1.1 which is incompatible.\n",
      "cookiecutter 1.7.2 requires MarkupSafe<2.0.0, but you have markupsafe 2.1.1 which is incompatible.\u001b[0m\n",
      "Successfully installed MarkupSafe-2.1.1 bert-extractive-summarizer-0.10.1 blis-0.7.7 catalogue-2.0.7 certifi-2021.10.8 charset-normalizer-2.0.12 click-8.0.4 cymem-2.0.6 filelock-3.6.0 huggingface-hub-0.5.1 idna-3.3 jinja2-3.1.1 joblib-1.1.0 langcodes-3.3.0 murmurhash-1.0.6 numpy-1.22.3 packaging-21.3 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 pyparsing-3.0.8 pyyaml-6.0 regex-2022.4.24 requests-2.27.1 sacremoses-0.0.49 scikit-learn-1.0.2 scipy-1.8.0 setuptools-62.1.0 six-1.16.0 smart-open-5.2.1 spacy-3.2.4 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.15 threadpoolctl-3.1.0 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.18.0 typer-0.4.1 typing-extensions-4.2.0 urllib3-1.26.9 wasabi-0.9.1\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.2.4-cp39-cp39-macosx_10_9_x86_64.whl (6.3 MB)\n",
      "Collecting click<8.1.0\n",
      "  Using cached click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Collecting numpy>=1.15.0\n",
      "  Using cached numpy-1.22.3-cp39-cp39-macosx_10_14_x86_64.whl (17.6 MB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.7-cp39-cp39-macosx_10_9_x86_64.whl (5.8 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp39-cp39-macosx_10_9_x86_64.whl (32 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp39-cp39-macosx_10_9_x86_64.whl (106 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting requests<3.0.0,>=2.13.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-62.1.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Using cached thinc-8.0.15-cp39-cp39-macosx_10_9_x86_64.whl (639 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Using cached srsly-2.4.3-cp39-cp39-macosx_10_9_x86_64.whl (457 kB)\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.1-py3-none-any.whl (132 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-cp39-cp39-macosx_10_9_x86_64.whl (2.7 MB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Using cached spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.6-cp39-cp39-macosx_10_9_x86_64.whl (18 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.1-py3-none-any.whl (27 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Using cached pyparsing-3.0.8-py3-none-any.whl (98 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp39-cp39-macosx_10_9_x86_64.whl (13 kB)\n",
      "Installing collected packages: typing-extensions, numpy, murmurhash, cymem, click, catalogue, wasabi, urllib3, typer, srsly, smart-open, setuptools, pyparsing, pydantic, preshed, MarkupSafe, idna, charset-normalizer, certifi, blis, tqdm, thinc, spacy-loggers, spacy-legacy, requests, pathy, packaging, langcodes, jinja2, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.2.0\n",
      "    Uninstalling typing-extensions-4.2.0:\n",
      "      Successfully uninstalled typing-extensions-4.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.3\n",
      "    Uninstalling numpy-1.22.3:\n",
      "      Successfully uninstalled numpy-1.22.3\n",
      "  Attempting uninstall: murmurhash\n",
      "    Found existing installation: murmurhash 1.0.6\n",
      "    Uninstalling murmurhash-1.0.6:\n",
      "      Successfully uninstalled murmurhash-1.0.6\n",
      "  Attempting uninstall: cymem\n",
      "    Found existing installation: cymem 2.0.6\n",
      "    Uninstalling cymem-2.0.6:\n",
      "      Successfully uninstalled cymem-2.0.6\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Uninstalling click-8.0.4:\n",
      "      Successfully uninstalled click-8.0.4\n",
      "  Attempting uninstall: catalogue\n",
      "    Found existing installation: catalogue 2.0.7\n",
      "    Uninstalling catalogue-2.0.7:\n",
      "      Successfully uninstalled catalogue-2.0.7\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 0.9.1\n",
      "    Uninstalling wasabi-0.9.1:\n",
      "      Successfully uninstalled wasabi-0.9.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.9\n",
      "    Uninstalling urllib3-1.26.9:\n",
      "      Successfully uninstalled urllib3-1.26.9\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.4.1\n",
      "    Uninstalling typer-0.4.1:\n",
      "      Successfully uninstalled typer-0.4.1\n",
      "  Attempting uninstall: srsly\n",
      "    Found existing installation: srsly 2.4.3\n",
      "    Uninstalling srsly-2.4.3:\n",
      "      Successfully uninstalled srsly-2.4.3\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 5.2.1\n",
      "    Uninstalling smart-open-5.2.1:\n",
      "      Successfully uninstalled smart-open-5.2.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 62.1.0\n",
      "    Uninstalling setuptools-62.1.0:\n",
      "      Successfully uninstalled setuptools-62.1.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.8\n",
      "    Uninstalling pyparsing-3.0.8:\n",
      "      Successfully uninstalled pyparsing-3.0.8\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.8.2\n",
      "    Uninstalling pydantic-1.8.2:\n",
      "      Successfully uninstalled pydantic-1.8.2\n",
      "  Attempting uninstall: preshed\n",
      "    Found existing installation: preshed 3.0.6\n",
      "    Uninstalling preshed-3.0.6:\n",
      "      Successfully uninstalled preshed-3.0.6\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.1\n",
      "    Uninstalling MarkupSafe-2.1.1:\n",
      "      Successfully uninstalled MarkupSafe-2.1.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.12\n",
      "    Uninstalling charset-normalizer-2.0.12:\n",
      "      Successfully uninstalled charset-normalizer-2.0.12\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2021.10.8\n",
      "    Uninstalling certifi-2021.10.8:\n",
      "      Successfully uninstalled certifi-2021.10.8\n",
      "  Attempting uninstall: blis\n",
      "    Found existing installation: blis 0.7.7\n",
      "    Uninstalling blis-0.7.7:\n",
      "      Successfully uninstalled blis-0.7.7\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.0\n",
      "    Uninstalling tqdm-4.64.0:\n",
      "      Successfully uninstalled tqdm-4.64.0\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.0.15\n",
      "    Uninstalling thinc-8.0.15:\n",
      "      Successfully uninstalled thinc-8.0.15\n",
      "  Attempting uninstall: spacy-loggers\n",
      "    Found existing installation: spacy-loggers 1.0.2\n",
      "    Uninstalling spacy-loggers-1.0.2:\n",
      "      Successfully uninstalled spacy-loggers-1.0.2\n",
      "  Attempting uninstall: spacy-legacy\n",
      "    Found existing installation: spacy-legacy 3.0.9\n",
      "    Uninstalling spacy-legacy-3.0.9:\n",
      "      Successfully uninstalled spacy-legacy-3.0.9\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "  Attempting uninstall: pathy\n",
      "    Found existing installation: pathy 0.6.1\n",
      "    Uninstalling pathy-0.6.1:\n",
      "      Successfully uninstalled pathy-0.6.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: langcodes\n",
      "    Found existing installation: langcodes 3.3.0\n",
      "    Uninstalling langcodes-3.3.0:\n",
      "      Successfully uninstalled langcodes-3.3.0\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.1\n",
      "    Uninstalling Jinja2-3.1.1:\n",
      "      Successfully uninstalled Jinja2-3.1.1\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.2.4\n",
      "    Uninstalling spacy-3.2.4:\n",
      "      Successfully uninstalled spacy-3.2.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.1 requires ruamel-yaml, which is not installed.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.3 which is incompatible.\n",
      "cookiecutter 1.7.2 requires Jinja2<3.0.0, but you have jinja2 3.1.1 which is incompatible.\n",
      "cookiecutter 1.7.2 requires MarkupSafe<2.0.0, but you have markupsafe 2.1.1 which is incompatible.\u001b[0m\n",
      "Successfully installed MarkupSafe-2.1.1 blis-0.7.7 catalogue-2.0.7 certifi-2021.10.8 charset-normalizer-2.0.12 click-8.0.4 cymem-2.0.6 idna-3.3 jinja2-3.1.1 langcodes-3.3.0 murmurhash-1.0.6 numpy-1.22.3 packaging-21.3 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 pyparsing-3.0.8 requests-2.27.1 setuptools-62.1.0 smart-open-5.2.1 spacy-3.2.4 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.15 tqdm-4.64.0 typer-0.4.1 typing-extensions-4.2.0 urllib3-1.26.9 wasabi-0.9.1\n",
      "Requirement already satisfied: nltk in ./opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: pywsd in ./opt/anaconda3/lib/python3.9/site-packages (1.2.4)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from pywsd) (1.22.3)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.9/site-packages (from pywsd) (1.16.0)\n",
      "Requirement already satisfied: nltk in ./opt/anaconda3/lib/python3.9/site-packages (from pywsd) (3.7)\n",
      "Requirement already satisfied: pandas in ./opt/anaconda3/lib/python3.9/site-packages (from pywsd) (1.3.4)\n",
      "Requirement already satisfied: wn in ./opt/anaconda3/lib/python3.9/site-packages (from pywsd) (0.9.1)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->pywsd) (1.1.0)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->pywsd) (8.0.4)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->pywsd) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->pywsd) (2022.4.24)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->pywsd) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./opt/anaconda3/lib/python3.9/site-packages (from pandas->pywsd) (2021.3)\n",
      "Requirement already satisfied: tomli in ./opt/anaconda3/lib/python3.9/site-packages (from wn->pywsd) (2.0.1)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.9/site-packages (from wn->pywsd) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->wn->pywsd) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->wn->pywsd) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->wn->pywsd) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./opt/anaconda3/lib/python3.9/site-packages (from requests->wn->pywsd) (1.26.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/dhanamjaya/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install git+https://github.com/boudinfl/pke.git\n",
    "!python -m spacy download en\n",
    "!pip install bert-extractive-summarizer --upgrade --force-reinstall\n",
    "!pip install spacy --upgrade --force-reinstall\n",
    "!pip install -U nltk\n",
    "!pip install -U pywsd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25ddf728",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text='''The five senses include sight, sound, taste, hearing and touch. Sight, like the other senses is closely related to other parts of our anatomy. The eye is connected to the brain and dependent upon the brain to interpret what we see.\n",
    "\n",
    "How we see depends upon the transfer of light. Light passes through the front of the eye (cornea) to the lens. The cornea and the lens help to focus the light rays onto the back of the eye (retina). The cells in the retina absorb and convert the light to electrochemical impulses which are transferred along the optic nerve and then to the brain.\n",
    "\n",
    "The eye works much the same as a camera. The shutter of a camera can close or open depending upon the amount of light needed to expose the film in the back of the camera. The eye, like the camera shutter, operates in the same way. The iris and the pupil control how much light to let into the back of the eye. When it is very dark, our pupils are very large, letting in more light. The lens of a camera is able to focus on objects far away and up close with the help of mirrors and other mechanical devices. The lens of the eye helps us to focus but sometimes needs some additional help in order to focus clearly. Glasses, contact lenses, and artificial lenses all help us to see more clearly. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2432c874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The five senses include sight, sound, taste, hearing and touch. Light passes through the front of the eye (cornea) to the lens. The iris and the pupil control how much light to let into the back of the eye. The lens of a camera is able to focus on objects far away and up close with the help of mirrors and other mechanical devices. The lens of the eye helps us to focus but sometimes needs some additional help in order to focus clearly.\n"
     ]
    }
   ],
   "source": [
    "from summarizer import Summarizer,TransformerSummarizer\n",
    "model = TransformerSummarizer(transformer_type=\"XLNet\",transformer_model_key=\"xlnet-base-cased\")\n",
    "result = model(full_text, min_length=60, max_length = 500 , ratio = 0.4)\n",
    "summarized_text = ''.join(result)\n",
    "print (summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5a44128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pke\n",
    "from pke.lang import stopwords\n",
    "\n",
    "def get_nouns_YAKE(text):\n",
    "    \n",
    "    out=[]\n",
    "    \n",
    "    # 1. create a YAKE extractor.\n",
    "    extractor = pke.unsupervised.YAKE()\n",
    "    \n",
    "    # 2. load the content of the document.\n",
    "    stoplist = stopwords.get('english')\n",
    "    \n",
    "    extractor.load_document(input=text,\n",
    "                            language='en',\n",
    "                            stoplist=stoplist,\n",
    "                            normalization=None)\n",
    "    \n",
    "    # 3. select {1-3}-grams not containing punctuation marks and not\n",
    "    #    beginning/ending with a stopword as candidates.\n",
    "    extractor.candidate_selection(n=3)\n",
    "    \n",
    "    \n",
    "    # 4. weight the candidates using YAKE weighting scheme, a window (in\n",
    "    #    words) for computing left/right contexts can be specified.\n",
    "    window = 2\n",
    "    use_stems = False # use stems instead of words for weighting\n",
    "    extractor.candidate_weighting(window=window,\n",
    "                              use_stems=use_stems)\n",
    "    threshold = 0.8\n",
    "    keyphrases = extractor.get_n_best(n=20, threshold=threshold)\n",
    "    \n",
    "    for key in keyphrases:\n",
    "         out.append(key[0])\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "58008407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords from Original Text are: \n",
      "\n",
      "['senses include sight', 'eye', 'light', 'include sight', 'senses include', 'camera', 'lens', 'sight', 'help', 'focus', 'senses', 'brain', 'sound', 'taste', 'hearing', 'touch', 'include', 'lens help', 'like', 'light passes']\n",
      "\n",
      "\n",
      "20\n",
      "\n",
      "Keywords from Summarized Version are: \n",
      "\n",
      "['senses include sight', 'eye', 'light', 'include sight', 'senses include', 'camera', 'lens', 'sight', 'help', 'focus', 'senses', 'sound', 'taste', 'hearing', 'touch', 'include', 'light passes']\n",
      "\n",
      "\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "keywords = get_nouns_YAKE(full_text) \n",
    "print(\"Keywords from Original Text are: \\n\")\n",
    "print (keywords)\n",
    "print('\\n')\n",
    "print('{}\\n'.format(len(keywords)))\n",
    "filtered_keys=[]\n",
    "for keyword in keywords:\n",
    "    if keyword.lower() in summarized_text.lower():\n",
    "        filtered_keys.append(keyword)\n",
    "\n",
    "print('Keywords from Summarized Version are: \\n')   \n",
    "print (filtered_keys)\n",
    "print('\\n')\n",
    "print(len(filtered_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58428d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flashtext\n",
      "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
      "Building wheels for collected packages: flashtext\n",
      "  Building wheel for flashtext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9310 sha256=8790c5c765565b09f36248fa194520d073bd73e9d9e620541ab4fe370ae3c0e6\n",
      "  Stored in directory: /Users/dhanamjaya/Library/Caches/pip/wheels/65/3c/c7/44672c5062c16d05760b1eaddbf611d2f6a4b715c6d6777418\n",
      "Successfully built flashtext\n",
      "Installing collected packages: flashtext\n",
      "Successfully installed flashtext-2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install flashtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e49a2c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'senses include sight': ['The five senses include sight, sound, taste, hearing and touch.'], 'eye': ['The lens of the eye helps us to focus but sometimes needs some additional help in order to focus clearly.', 'The iris and the pupil control how much light to let into the back of the eye.', 'Light passes through the front of the eye (cornea) to the lens.'], 'light': ['The iris and the pupil control how much light to let into the back of the eye.'], 'camera': ['The lens of a camera is able to focus on objects far away and up close with the help of mirrors and other mechanical devices.'], 'lens': ['The lens of a camera is able to focus on objects far away and up close with the help of mirrors and other mechanical devices.', 'The lens of the eye helps us to focus but sometimes needs some additional help in order to focus clearly.', 'Light passes through the front of the eye (cornea) to the lens.'], 'help': ['The lens of a camera is able to focus on objects far away and up close with the help of mirrors and other mechanical devices.', 'The lens of the eye helps us to focus but sometimes needs some additional help in order to focus clearly.'], 'focus': ['The lens of a camera is able to focus on objects far away and up close with the help of mirrors and other mechanical devices.', 'The lens of the eye helps us to focus but sometimes needs some additional help in order to focus clearly.', 'The lens of the eye helps us to focus but sometimes needs some additional help in order to focus clearly.'], 'sound': ['The five senses include sight, sound, taste, hearing and touch.'], 'taste': ['The five senses include sight, sound, taste, hearing and touch.'], 'hearing': ['The five senses include sight, sound, taste, hearing and touch.'], 'touch': ['The five senses include sight, sound, taste, hearing and touch.'], 'light passes': ['Light passes through the front of the eye (cornea) to the lens.']}\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from flashtext import KeywordProcessor\n",
    "def tokenize_sentences(text):\n",
    "    sentences = [sent_tokenize(text)]\n",
    "    sentences = [y for x in sentences for y in x]\n",
    "    # Remove any short sentences less than 20 letters.\n",
    "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
    "    return sentences\n",
    "def get_sentences_for_keyword(keywords, sentences):\n",
    "    keyword_processor = KeywordProcessor()\n",
    "    keyword_sentences = {}\n",
    "    for word in keywords:\n",
    "        keyword_sentences[word] = []\n",
    "        keyword_processor.add_keyword(word)\n",
    "    for sentence in sentences:\n",
    "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
    "        for key in keywords_found:\n",
    "            keyword_sentences[key].append(sentence)\n",
    "        for key in keyword_sentences.keys():\n",
    "            values = keyword_sentences[key]\n",
    "            values = sorted(values, key=len, reverse=True)\n",
    "            keyword_sentences[key] = values\n",
    "    return keyword_sentences\n",
    "\n",
    "sentences = tokenize_sentences(summarized_text)\n",
    "keyword_sentence_mapping = get_sentences_for_keyword(filtered_keys, sentences)\n",
    "\n",
    "for keyword in list(keyword_sentence_mapping):\n",
    "    if len(keyword_sentence_mapping[keyword])==0:\n",
    "        keyword_sentence_mapping.pop(keyword)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print (keyword_sentence_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c6a1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pywsd==1.0.2\n",
      "  Downloading pywsd-1.0.2.tar.gz (8.6 kB)\n",
      "Requirement already satisfied: nltk in ./opt/anaconda3/lib/python3.9/site-packages (from pywsd==1.0.2) (3.7)\n",
      "Requirement already satisfied: numpy in ./opt/anaconda3/lib/python3.9/site-packages (from pywsd==1.0.2) (1.22.3)\n",
      "Requirement already satisfied: joblib in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->pywsd==1.0.2) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->pywsd==1.0.2) (2022.4.24)\n",
      "Requirement already satisfied: tqdm in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->pywsd==1.0.2) (4.64.0)\n",
      "Requirement already satisfied: click in ./opt/anaconda3/lib/python3.9/site-packages (from nltk->pywsd==1.0.2) (8.0.4)\n",
      "Building wheels for collected packages: pywsd\n",
      "  Building wheel for pywsd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pywsd: filename=pywsd-1.0.2-py3-none-any.whl size=12122 sha256=192e46a126b305d879bae8fa624497de15251c8d912a48794ff14ca85b027746\n",
      "  Stored in directory: /Users/dhanamjaya/Library/Caches/pip/wheels/8a/b7/26/ca558b21cde5b18c34591fbd5af774a272cd48680e0084e3b1\n",
      "Successfully built pywsd\n",
      "Installing collected packages: pywsd\n",
      "  Attempting uninstall: pywsd\n",
      "    Found existing installation: pywsd 1.2.4\n",
      "    Uninstalling pywsd-1.2.4:\n",
      "      Successfully uninstalled pywsd-1.2.4\n",
      "Successfully installed pywsd-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pywsd==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8d11bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(keyword_sentence_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "151c0cdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################################################\n",
      "NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \n",
      "#############################################################################\n",
      "\n",
      "\n",
      "1) The lens of the  _______  helps us to focus but sometimes needs some additional help in order to focus clearly.\n",
      "\t a )   Discretion\n",
      "\t b )   Eye\n",
      "\t c )   Common Sense\n",
      "\t d )   Injudiciousness\n",
      "\n",
      "More options:  ['Judiciousness'] \n",
      "\n",
      "\n",
      "2) The iris and the pupil control how much  _______  to let into the back of the eye.\n",
      "\t a )   Light\n",
      "\t b )   Sparkle\n",
      "\t c )   Leer\n",
      "\n",
      "More options:  [] \n",
      "\n",
      "\n",
      "3) The lens of a  _______  is able to focus on objects far away and up close with the help of mirrors and other mechanical devices.\n",
      "\t a )   Camera\n",
      "\t b )   Developer\n",
      "\t c )   Clapperboard\n",
      "\t d )   Enlarger\n",
      "\n",
      "More options:  ['Flash', 'Light Meter', 'Photographic Paper', 'Sensitometer'] \n",
      "\n",
      "\n",
      "4) The  _______  of a camera is able to focus on objects far away and up close with the help of mirrors and other mechanical devices.\n",
      "\t a )   Autofocus\n",
      "\t b )   Lens\n",
      "\t c )   Camera Lucida\n",
      "\t d )   Biprism\n",
      "\n",
      "More options:  ['Coelostat', 'Collimator', 'Diffraction Grating', 'Diffuser', 'Finder', 'Kerr Cell', 'Laser', 'Nicol Prism', 'Planetarium', 'Polarimeter', 'Prism', 'Projector', 'Rochon Prism', 'Stereoscope', 'Viewer'] \n",
      "\n",
      "\n",
      "5) The lens of a camera is able to focus on objects far away and up close with the  _______  of mirrors and other mechanical devices.\n",
      "\t a )   Aid\n",
      "\t b )   Help\n",
      "\t c )   Attempt\n",
      "\t d )   Acting\n",
      "\n",
      "More options:  ['Behavior', 'Burst', 'Buzz', 'Calibration', 'Ceremony', 'Concealment', 'Continuance', 'Control', 'Creation', 'Cup Of Tea', 'Demand', 'Dismantling', 'Diversion', 'Domesticity', 'Education', 'Energizing'] \n",
      "\n",
      "\n",
      "6) The lens of a camera is able to  _______  on objects far away and up close with the help of mirrors and other mechanical devices.\n",
      "\t a )   Study\n",
      "\t b )   Specialism\n",
      "\t c )   Focus\n",
      "\n",
      "More options:  [] \n",
      "\n",
      "\n",
      "7) The five senses include sight,  _______ , taste, hearing and touch.\n",
      "\t a )   Accompaniment\n",
      "\t b )   Sound\n",
      "\t c )   Appearance\n",
      "\t d )   Accident\n",
      "\n",
      "More options:  ['Avalanche', 'Beginning', 'Boom', 'Case', 'Change', 'Collapse', 'Contact', 'Convergence', 'Crash', 'Destiny', 'Disappearance', 'Discharge', 'Ending', 'Episode', 'Error', 'Eventuality'] \n",
      "\n",
      "\n",
      "8) The five senses include sight, sound,  _______ , hearing and touch.\n",
      "\t a )   Smell\n",
      "\t b )   Hearing\n",
      "\t c )   Sight\n",
      "\t d )   Taste\n",
      "\n",
      "More options:  ['Touch'] \n",
      "\n",
      "\n",
      "9) The five senses include sight, sound, taste,  _______  and touch.\n",
      "\t a )   Lipreading\n",
      "\t b )   Hearing\n",
      "\t c )   Listening\n",
      "\t d )   Look\n",
      "\n",
      "More options:  ['Smell', 'Taste'] \n",
      "\n",
      "\n",
      "10) The five senses include sight, sound, taste, hearing and  _______ .\n",
      "\t a )   Touch\n",
      "\t b )   Smell\n",
      "\t c )   Hearing\n",
      "\t d )   Sight\n",
      "\n",
      "More options:  ['Taste'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from pywsd.similarity import max_similarity\n",
    "from pywsd.lesk import adapted_lesk\n",
    "from pywsd.lesk import simple_lesk\n",
    "from pywsd.lesk import cosine_lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Distractors from Wordnet\n",
    "def get_distractors_wordnet(syn,word):\n",
    "    distractors=[]\n",
    "    word= word.lower()\n",
    "    orig_word = word\n",
    "    if len(word.split())>0:\n",
    "        word = word.replace(\" \",\"_\")\n",
    "    hypernym = syn.hypernyms()\n",
    "    if len(hypernym) == 0: \n",
    "        return distractors\n",
    "    for item in hypernym[0].hyponyms():\n",
    "        name = item.lemmas()[0].name()\n",
    "        #print (\"name \",name, \" word\",orig_word)\n",
    "        if name == orig_word:\n",
    "            continue\n",
    "        name = name.replace(\"_\",\" \")\n",
    "        name = \" \".join(w.capitalize() for w in name.split())\n",
    "        if name is not None and name not in distractors:\n",
    "            distractors.append(name)\n",
    "    return distractors\n",
    "\n",
    "def get_wordsense(sent,word):\n",
    "    word= word.lower()\n",
    "    \n",
    "    if len(word.split())>0:\n",
    "        word = word.replace(\" \",\"_\")\n",
    "    \n",
    "    \n",
    "    synsets = wn.synsets(word,'n')\n",
    "    if synsets:\n",
    "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
    "        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
    "        lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
    "        return synsets[lowest_index]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Distractors from http://conceptnet.io/\n",
    "def get_distractors_conceptnet(word):\n",
    "    word = word.lower()\n",
    "    original_word= word\n",
    "    if (len(word.split())>0):\n",
    "        word = word.replace(\" \",\"_\")\n",
    "    distractor_list = [] \n",
    "    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
    "    obj = requests.get(url).json()\n",
    "\n",
    "    for edge in obj['edges']:\n",
    "        link = edge['end']['term'] \n",
    "\n",
    "        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
    "        obj2 = requests.get(url2).json()\n",
    "        for edge in obj2['edges']:\n",
    "            word2 = edge['start']['label']\n",
    "            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
    "                distractor_list.append(word2)\n",
    "                   \n",
    "    return distractor_list\n",
    "\n",
    "key_distractor_list = {}\n",
    "\n",
    "for keyword in keyword_sentence_mapping:\n",
    "    wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
    "    if wordsense:\n",
    "        distractors = get_distractors_wordnet(wordsense,keyword)\n",
    "        if len(distractors) ==0:\n",
    "            distractors = get_distractors_conceptnet(keyword)\n",
    "        if len(distractors) != 0:\n",
    "            key_distractor_list[keyword] = distractors\n",
    "    else:\n",
    "        \n",
    "        distractors = get_distractors_conceptnet(keyword)\n",
    "        if len(distractors) != 0:\n",
    "            key_distractor_list[keyword] = distractors\n",
    "\n",
    "index = 1\n",
    "print (\"#############################################################################\")\n",
    "print (\"NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \")\n",
    "print (\"#############################################################################\\n\\n\")\n",
    "for each in key_distractor_list:\n",
    "    sentence = keyword_sentence_mapping[each][0]\n",
    "    pattern = re.compile(each, re.IGNORECASE)\n",
    "    output = pattern.sub( \" _______ \", sentence)\n",
    "    print (\"%s)\"%(index),output)\n",
    "    choices = [each.capitalize()] + key_distractor_list[each]\n",
    "    top4choices = choices[:4]\n",
    "    random.shuffle(top4choices)\n",
    "    optionchoices = ['a','b','c','d']\n",
    "    for idx,choice in enumerate(top4choices):\n",
    "        print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n",
    "    print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf50a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caca4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
